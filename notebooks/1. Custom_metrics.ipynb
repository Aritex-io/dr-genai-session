{
	"cells": [
		{
			"id": "65e71b16aa6579a43dafd0b2",
			"cell_type": "markdown",
			"source": "# Creating custom metrics for your Large Language Model (LLM)\n\nWithin this Jupyter notebook, you'll discover the seamless process of crafting and implementing custom metrics using code. This invaluable functionality empowers users to deploy metrics tailored precisely to their unique business requirements. Whether you're tracking specialized metrics or catering to distinct business needs, this tutorial equips you with the tools to seamlessly integrate custom metrics into your workflow.",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65e71b0dabc5c780738f8b1c",
			"cell_type": "markdown",
			"source": "## Installation\nEnsure you have the required libraries installed by executing the following commands in your Jupyter notebook:",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65c4c057ea14b3b9584f84b7",
			"cell_type": "code",
			"source": "!pip install -q datarobot datarobotx[llm] tiktoken ",
			"metadata": {
				"name": "First cell",
				"collapsed": true,
				"scrolled": "auto",
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [],
			"execution_count": null
		},
		{
			"id": "65eb75286a58fec6f4dd9429",
			"cell_type": "markdown",
			"source": "## Import modules",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65eb74f1fb9cd6f23202c216",
			"cell_type": "code",
			"source": "import os\nimport requests\nimport tiktoken\nimport pandas as pd\nfrom datetime import datetime",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [],
			"execution_count": null
		},
		{
			"id": "65eb74d2fb9cd6f23202c20c",
			"cell_type": "markdown",
			"source": "## Load secrets",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65eb74ce6a58fec6f4dd940d",
			"cell_type": "code",
			"source": "API_URL = os.environ['API_URL']\nPRED_API_URL = os.environ['PRED_API_URL']\nAPI_KEY = os.environ['API_KEY']\nDEPLOYMENT_ID = os.environ['DEPLOYMENT_ID'] #DEPLOYMENT ID\nCUSTOM_METRIC_ID = os.environ['CUSTOM_METRIC_ID'] #Metric ID\nDATAROBOT_KEY = os.environ['DATAROBOT_KEY'] #DEPLOYMENT ID\nMODEL_PACKAGE_ID = None",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [],
			"execution_count": null
		},
		{
			"id": "65e71bebaa6579a43dafd102",
			"cell_type": "markdown",
			"source": "## Creating custom metric function\nTo understand the Total Cost of the solution, the organization will build a metric around the pricing of the GPT 3.5 API provided by Azure. The following function calculates the price per prediction call using token counts calculated using Tiktoken. It then multiplies the token counts with the price per token provided in the Azure OpenAl pricing\npage. If the LLM is self-hosted, metrics around the compute cost are relevant for the organization.",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65c4c15446ba6b4a1eea60a5",
			"cell_type": "code",
			"source": "# Obtain encoding for the specified model\nencoding = tiktoken.get_encoding(\"cl100k_base\")\n\n# Define custom metrics functions\ndef get_gpt_token_count(text):\n    \"\"\"\n    Counts the number of tokens in the given text.\n\n    Args:\n        text (str): Input text to count tokens.\n\n    Returns:\n        int: Number of tokens in the text.\n    \"\"\"    \n    return len(encoding.encode(text))\n\ndef get_gpt_3_5_cost(\n    prompt, response, prompt_token_cost=0.0015 / 1000, response_token_cost=0.002 / 1000\n):\n    \"\"\"\n    Calculates the cost of generating a response using GPT, based on token counts and token costs.\n\n    Args:\n        prompt (str): Prompt text provided to the model.\n        response (str): Generated response text.\n        prompt_token_cost (float): Cost per token for the prompt. Default is 0.0015 / 1000.\n        response_token_cost (float): Cost per token for the response. Default is 0.002 / 1000.\n\n    Returns:\n        float: Cost of generating the response.\n    \"\"\"    \n    return (\n        get_gpt_token_count(prompt) * prompt_token_cost\n        + get_gpt_token_count(response) * response_token_cost\n    )\n\n# Example usage\nprompt = \"How can we improve renewable energy?\"\nresponse = \"By investing in solar and wind technologies.\"\n\n# Calculate custom metric\ncost = get_gpt_3_5_cost(prompt, response)\nprint(\"Cost of generating response:\", cost)\n",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [
				{
					"output_type": "execute_result",
					"execution_count": 2,
					"data": {
						"text/plain": "Cost of generating response: 2.65e-05\n"
					},
					"metadata": {}
				}
			],
			"execution_count": 2
		},
		{
			"id": "65eb763e6a58fec6f4dd9481",
			"cell_type": "markdown",
			"source": "## Test predictions on deployed model",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65eb034d6a58fec6f4dd7033",
			"cell_type": "code",
			"source": "def make_predictions(inputText):\n    \"Make predictions using the specified input text and DataRobot deployment.\"\n    \n    data = \"promptText\\n\" + inputText\n    \n    headers={\n                \"Content-Type\": \"text/plain; charset=UTF-8\",\n                \"Authorization\": \"Bearer \" + API_KEY,\n                \"DataRobot-Key\": DATAROBOT_KEY\n            }\n    \n    predictions_response = requests.post(\n            PRED_API_URL.format(deployment_id=DEPLOYMENT_ID),\n            data=data,\n            headers=headers,\n    )\n    return predictions_response\n\ninputText = \"What is romance?\"\npredictions_response = make_predictions(inputText)\npredictions_response.json()",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [
				{
					"output_type": "execute_result",
					"execution_count": 4,
					"data": {
						"text/plain": "{'data': [{'rowId': 0,\n   'prediction': 'Romance is a genre of literature, film, and television that focuses on passionate love stories that often have a happy ending. The element of drama, emotion, and intimacy characterizes romantic stories typically unfold between two people who are attracted to each other but face some obstacle, whether internal or external, that keeps them from being together right away. The genre first emerged in the late eighteenth century and has been consistently popular ever since.',\n   'predictionValues': [{'label': 'resultText',\n     'value': 'Romance is a genre of literature, film, and television that focuses on passionate love stories that often have a happy ending. The element of drama, emotion, and intimacy characterizes romantic stories typically unfold between two people who are attracted to each other but face some obstacle, whether internal or external, that keeps them from being together right away. The genre first emerged in the late eighteenth century and has been consistently popular ever since.'}],\n   'deploymentApprovalStatus': 'APPROVED'}]}"
					},
					"metadata": {}
				}
			],
			"execution_count": 4
		},
		{
			"id": "65eb76864f3f922ae5bce317",
			"cell_type": "markdown",
			"source": "## Upload custom metrics\nThis function submit_custom_metric records values for an existing custom metric on a deployment. It takes the API URL, API key, deployment ID, custom metric ID, model package ID, and the metric value as inputs, and posts the data to the specified endpoint.",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "markdown"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			}
		},
		{
			"id": "65eb0b886a58fec6f4dd72c2",
			"cell_type": "code",
			"source": "def submit_custom_metric(API_URL,API_KEY,DEPLOYMENT_ID,CUSTOM_METRIC_ID,MODEL_PACKAGE_ID, metric):\n    \"\"\"Record values for an existing custom metric on a deployment\"\"\"\n    \n    HEADERS = {\n    'Authorization': 'Bearer {}'.format(API_KEY),\n    'User-Agent': 'IntegrationSnippet-Requests',\n    }\n    time_ = datetime.today().strftime(\"%m/%d/%Y %I:%M %p\")\n    rows = [\n        {\"timestamp\": ts.isoformat(), \"value\": value}\n        for ts, value in zip([pd.to_datetime(time_)], [metric])\n    ]\n    response = requests.post(\n        API_URL.format(DEPLOYMENT_ID, CUSTOM_METRIC_ID),\n        json={'modelPackageId': MODEL_PACKAGE_ID, 'buckets': rows,},\n        headers=HEADERS,\n    )\n    response.raise_for_status()",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [],
			"execution_count": null
		},
		{
			"id": "65c4d0c946ba6b4a1eea6579",
			"cell_type": "code",
			"source": "submit_custom_metric(\n    API_URL,\n    API_KEY,\n    DEPLOYMENT_ID,\n    CUSTOM_METRIC_ID,\n    MODEL_PACKAGE_ID,\n    get_gpt_3_5_cost(inputText, predictions_response.json()[\"data\"][0][\"prediction\"]),\n)",
			"metadata": {
				"collapsed": false,
				"scrolled": false,
				"datarobot": {
					"language": "python"
				},
				"hide_code": false,
				"hide_results": false,
				"disable_run": false,
				"chart_settings": null,
				"custom_metric_settings": null,
				"custom_llm_metric_settings": null,
				"dataframe_view_options": null
			},
			"outputs": [],
			"execution_count": null
		}
	],
	"metadata": {
		"kernelspec": {
			"name": "python",
			"language": "python",
			"display_name": "Python 3.9.18"
		},
		"language_info": {
			"name": "python",
			"version": ""
		}
	},
	"nbformat": 4,
	"nbformat_minor": 5
}